

# üöÄ Bank Customer Subscription Prediction using MLOps
---

### üõ†Ô∏è FastAPI ¬∑ Streamlit ¬∑ Airflow ¬∑ MLflow ¬∑ DVC ¬∑ Prometheus ¬∑ Grafana ¬∑ LLMs ¬∑ Docker ¬∑ CI/CD

---

## üìå Project Summary

This project is a complete **MLOps pipeline** to predict whether a bank customer will subscribe to a term deposit based on campaign data. It integrates model training, monitoring, CI/CD automation, and explainability‚Äîall running within Docker containers and tracked using industry-standard tools.

---

## üß± Project Folder Structure

```
üìÅ .dvc/                    ‚Üí DVC configurations  
üìÅ .github/workflows/       ‚Üí GitHub Actions (CI/CD)  
üìÅ airflow/                 ‚Üí Airflow DAGs (3 DAGs)  
üìÅ BACKEND/                 ‚Üí FastAPI app (serving model)  
üìÅ FRONTEND/                ‚Üí Streamlit app (user interaction)  
üìÅ Database_connection/     ‚Üí PostgreSQL scripts  
üìÅ Drift_Detector/          ‚Üí Evidently for drift detection  
üìÅ llm_explainer/           ‚Üí LLM-based prediction explanation  
üìÅ mlflow/                  ‚Üí MLflow tracking setup  
üìÅ monitoring/              ‚Üí Prometheus + Grafana setup  
üìÅ scripts_dvc/             ‚Üí Data versioning scripts  
üìÅ src/                     ‚Üí Source code  
üìÑ docker-compose.yml       ‚Üí Docker orchestration  
```

---

## üß† Tools & Frameworks Used

| Tool/Tech             | Purpose                                          |
| --------------------- | ------------------------------------------------ |
| üêç Python             | Core programming language                        |
| üì¶ DVC                | Data versioning                                  |
| üìã MLflow             | Model training tracking, registry, and artifacts |
| ‚öôÔ∏è Airflow            | Pipeline scheduling and automation with 3 DAGs   |
| üß† FastAPI            | REST API to serve the ML model                   |
| üåê Streamlit          | UI for making and viewing predictions            |
| üìâ Evidently          | Drift detection in real-time                     |
| üìä Prometheus/Grafana | Metrics monitoring for system and models         |
| üê≥ Docker & DockerHub | Containerization and image push                  |
| üîê PostgreSQL         | Structured database for input/output storage     |
| üß† LLM Explainer      | Explains predictions using OpenAI API            |
| üöÄ GitHub Actions     | CI/CD: test, build, push containers              |

---

## üóÉÔ∏è PostgreSQL Schema

* **Database**: `banking_costumer_data`
* **Tables**:

  * `temp_table_new_costumer` ‚Üí temporary table for incoming data
  * `banking_new_data_history` ‚Üí historical logs used in retraining

---

## üîÑ Airflow DAGs

| DAG Name          | Functionality                                   |
| ----------------- | ----------------------------------------------- |
| `drift_dag`       | Checks for data/model drift                     |
| `etl_retarin_dag` | ETL and retraining logic                        |
| `retrain_dag`     | Complete retrain + model registration in MLflow |

---

## üìä Monitoring

* **Prometheus** collects metrics for model serving, system resource usage.
* **Grafana** displays real-time dashboards.
* **Evidently** tracks drift in production data and triggers retraining DAG.

---

## üîç Dataset Overview

### üìû Bank Marketing (Term Deposit Subscription)

* **Source**: [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing)
* **Rows**: 45,211 | **Features**: 17 + 1 Target

| Column      | Description                         |
| ----------- | ----------------------------------- |
| `age`       | Age of the client                   |
| `job`       | Type of job (admin, services, etc.) |
| `marital`   | Marital status                      |
| `education` | Education level                     |
| `default`   | Has credit in default               |
| `balance`   | Yearly balance                      |
| `housing`   | Has housing loan?                   |
| `loan`      | Has personal loan?                  |
| `contact`   | Contact type                        |
| `duration`  | Call duration                       |
| `campaign`  | Number of contacts in campaign      |
| `pdays`     | Days since last contact             |
| `previous`  | Past contacts                       |
| `poutcome`  | Outcome of previous campaign        |
| `y`         | **Target** (Subscribed: yes/no)     |

---

## üê≥ Docker + CI/CD

### ‚úÖ GitHub Actions CI Workflow

```yaml
name: CI to DockerHub

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Log in to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build Docker image
        run: docker build -t anuragraj03/bank-marketing-mlops .

      - name: Push to DockerHub
        run: docker push anuragraj03/bank-marketing-mlops
```

---

## üîß How to Run Locally

### 1. Install Requirements

```bash
pip install -r requirements.txt
```

### 2. Set up Environment Variables

```bash
export OPENAI_API_KEY=your_openai_api_key_here
```

### 3. Start with Docker

```bash
docker-compose up --build
```

---

## ‚öôÔ∏è Flow Diagram (Text)

graph TD

%% Initial Stage - Data Processing from src folder
A1[Raw Data] --> A2[Preprocessing - src/]
A2 --> A3[Data Ingestion - src/]
A3 --> A4[Model Training - src/]
A4 --> A5[Register Model + Artifacts - MLflow]

%% FastAPI Serving
A5 --> B1[Serve Model via FastAPI]

%% Streamlit Interaction
B1 --> C1[UI - Streamlit App]
C1 --> C2[User Enters New Data]
C2 --> C3[New Data Stored in PostgreSQL]

%% Airflow ETL + Retrain
C3 --> D1[Trigger Airflow DAG - etl_retarin_dag]
D1 --> D2[Extract Script]
D2 --> D3[Transform Script]
D3 --> D4[Load Script]
D4 --> D5[Retrain Script]
D5 --> A5

%% Drift Detection DAG
C3 --> E1[Airflow DAG - drift_dag]
E1 --> E2{Drift Detected?}
E2 -->|Yes| D1
E2 -->|No| F1[Continue Serving]

%% Monitoring Stack
B1 --> G1[Prometheus + Grafana - Real-time Monitoring]
E1 --> G1

%% CI/CD Automation
H1[GitHub Actions CI Pipeline]
H1 --> H2[Build & Test]
H2 --> H3[Push Docker Image to DockerHub]
H3 --> B1

%% Output + Explainability
C1 --> I1[Prediction Output + LLM Explainer]

```

---

## ‚ö†Ô∏è Notes & Prerequisites

* Set up your own OpenAI API key for LLM-based explanations.
* PostgreSQL must be running for real-time storage.
* Docker + DockerHub credentials must be added as GitHub Secrets:

  * `DOCKER_USERNAME`
  * `DOCKER_PASSWORD`

---

## üß† Use-Cases

| Use Case             | Reason                                                         |
| -------------------- | -------------------------------------------------------------- |
| Predict subscription | Direct use in marketing and targeting                          |
| Explain predictions  | Helps marketing managers understand model output (LLMs + SHAP) |
| Monitor drift        | Prevents outdated models from hurting performance              |
| Real-time dashboard  | DevOps-friendly setup for live system health monitoring        |

---

## üìú License

This repository and dataset are distributed under the [CC BY 4.0 License](https://creativecommons.org/licenses/by/4.0/). Please give credit to the original authors.

---

## üôå Acknowledgments

* **Dataset**: S√©rgio Moro, Paulo Rita, Paulo Cortez (2014)
* **Inspiration**: Full-stack MLOps pipelines using MLflow, Docker, DVC, and FastAPI.


